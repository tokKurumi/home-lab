#import "@preview/modern-g7-32:0.2.0": abstract, appendix-heading, appendixes, enum-numbering, gost


#show: gost.with(
  text-size: (default: 14pt, small: 10pt),
  indent: 1.25cm,
  city: "Саранск",
  hide-title: true,
  pagination-align: center,
  margin: (
    left: 30mm,
    right: 15mm,
    top: 20mm,
    bottom: 20mm,
  ),
  add-pagebreaks: true,
)

#counter(page).update(3)

#abstract(
  "никто не читает теги",
)[
  Текст реферата
]

#outline()

= Введение

Традиционный подход к хранению данных полагается на облачные сервисы — удобные, масштабируемые, но контролируемые третьими лицами. Такая модель несёт серьёзные риски:

- *Зависимость от провайдера*. Отключение интернета, блокировка сервиса или закрытие компании означают потерю доступа к данным.
- *Отсутствие контроля над приватностью*. Облачные провайдеры хранят и обрабатывают личную информацию по своим правилам. GDPR и подобные законы лишь ограничивают, но не исключают обработку данных.
- *Постоянные утечки*. Историческое количество инцидентов безопасности показывает, что централизованные хранилища — привлекательная цель для атак.
- *Финансовая зависимость*. Цены растут, условия меняются, сервисы закрываются.

Self-hosted инфраструктура предлагает альтернативу: полный контроль над данными на собственном оборудовании, независимость от внешних сервисов (кроме интернет-провайдера), и способность адаптировать систему под конкретные нужды.

Данная работа описывает проектирование и развертывание домашней лаборатории на базе Docker, которая решает указанные проблемы через комбинацию открытого программного обеспечения, контейнеризации и принципов сетевой безопасности. Результат — полнофункциональная мультиконтейнерная инфраструктура для управления медиа-контентом, мониторинга, и безопасного удалённого доступа.

= Целевая аудитория и применение

== Для кого предназначена эта работа

Проект ориентирован на три категории пользователей:

- *Студенты и исследователи*. Изучение архитектуры распределённых систем, контейнеризации, сетевой безопасности на практическом примере.
- *Системные администраторы и DevOps инженеры*. Опыт работы с Docker Compose, конфигурированием микросервисов, управлением инфраструктурой.
- *Энтузиасты и продвинутые пользователи*. Создание собственного медиа-сервера с полным контролем, альтернатива облачным сервисам.

== Уровни сложности реализации

Инфраструктура поддерживает прогрессивное усложнение:

- *Базовая конфигурация*. Развертывание медиа-сервера (Jellyfin) и торрент-клиента (qBittorrent) с VPN защитой за 15–20 минут с использованием именованных томов Docker.
- *Промежуточная конфигурация*. Добавление обратного прокси (Nginx Proxy Manager), локальной DNS системы, интеграция с собственным доменом через Cloudflare.
- *Расширенная конфигурация*. Полная автоматизация медиа-контента (Sonarr, Radarr, Lidarr), обработка файлов (FileFlows), мониторинг (Prometheus, Grafana), безопасный удалённый доступ через VPN.

== Основные возможности

Инфраструктура включает набор интегрированных сервисов, каждый из которых решает определённую задачу в экосистеме домашней лаборатории. От управления медиа-контентом до обеспечения безопасного удалённого доступа — система охватывает полный цикл работы с данными. Полный перечень функциональности и соответствующих компонентов представлен в таблице @capabilities-table, которая демонстрирует разнообразие возможностей и гибкость архитектуры.

#figure(
  table(
    columns: 3,
    table.header([Возможность], [Назначение], [Используемые сервисы]),
    [Управление медиа],
    [Автоматизация скачивания контента, управление индексерами и обработка запросов пользователей],
    [Sonarr, Radarr, Lidarr, Prowlarr, Jellyseerr],

    [Потоковая передача],
    [Воспроизведение медиа на различных устройствах, интеграция с Discord],
    [Jellyfin, Discord Music Bot],

    [Защищённое скачивание], [Торрент-загрузки через VPN для приватности], [qBittorrent, WireGuard],
    [Транскодирование], [Конвертация видео и аудио в оптимальные форматы], [FileFlows],
    [Обратное прокси], [Единая точка входа для всех сервисов с SSL/TLS], [Nginx Proxy Manager],
    [Мониторинг инфраструктуры], [Сбор метрик и визуализация системы], [Prometheus, Grafana, Node Exporter],
    [DNS и управление доменами],
    [Локальное разрешение имён с DOH/TOH и интеграция с внешним доменом],
    [AdGuardHome, Cloudflare],

    [Удалённый доступ], [Безопасное подключение с домашней сети извне], [WireGuard VPN],
  ),
  caption: [Основные возможности домашней лаборатории],
) <capabilities-table>

= Архитектура инфраструктуры

== Обзор компонентов

Система состоит из 14 основных сервисов, организованных по функциональным блокам. Каждый компонент работает в изолированном контейнере Docker и взаимодействует с другими через виртуальные сети и API.

#figure(
  table(
    columns: 4,
    table.header([Сервис], [Функция], [Порт], [Блок]),
    [#link("https://github.com/Fallenbagel/jellyseerr")[Jellyseerr]], [Интерфейс запросов], [5055], [Управление медиа],
    [#link("https://sonarr.tv/")[Sonarr]], [Автоматизация сериалов], [8989], [Управление медиа],
    [#link("https://radarr.video/")[Radarr]], [Автоматизация фильмов], [7878], [Управление медиа],
    [#link("https://lidarr.audio/")[Lidarr]], [Автоматизация музыки], [8686], [Управление медиа],
    [#link("https://prowlarr.com/")[Prowlarr]], [Управление индексерами], [9696], [Управление медиа],
    [#link("https://jellyfin.org/")[Jellyfin]], [Потоковая передача медиа], [8096], [Потоковая передача],
    [#link("https://github.com/manuel-rw/jellyfin-discord-music-bot")[Discord Music Bot]],
    [Воспроизведение музыки в Discord],
    [3000],
    [Потоковая передача],

    [#link("https://www.qbittorrent.org/")[qBittorrent]], [Торрент-клиент (через VPN)], [8080], [Загрузки],
    [#link("https://github.com/revenz/FileFlows")[FileFlows]], [Транскодирование видео], [5000], [Обработка файлов],
    [#link("https://www.wireguard.com/")[WireGuard]], [VPN сервер], [51820], [Сеть],
    [#link("https://adguard.com/adguard-home/home.html")[AdGuardHome]], [DNS с DOH/TOH], [53, 853, 443], [Сеть],
    [#link("https://nginxproxymanager.com/")[Nginx Proxy Manager]], [Обратный прокси + SSL], [80, 81, 443], [Сеть],
    [#link("https://www.cloudflare.com/")[Cloudflare]], [DNS и управление доменом], [—], [Сеть],
    [#link("https://prometheus.io/")[Prometheus]], [Сбор метрик], [9090], [Мониторинг],
    [#link("https://grafana.com/")[Grafana]], [Визуализация графиков], [3000], [Мониторинг],
    [#link("https://github.com/prometheus/node_exporter")[Node Exporter]], [Метрики хоста], [9100], [Мониторинг],
    [#link("https://www.portainer.io/")[Portainer]],
    [Управление Docker контейнерами],
    [8000, 9000, 9443],
    [Инфраструктура],

    [#link("https://github.com/dani-garcia/vaultwarden")[Vaultwarden]], [Хранилище паролей], [80], [Инфраструктура],
    [#link("https://homarr.dev/")[Homarr (Dashboard)]], [Главная страница и управление], [7575], [Инфраструктура],
    [#link("https://openspeedtest.com/")[OpenSpeedTest]],
    [Тестирование скорости интернета],
    [3000-3001, 8080],
    [Инфраструктура],

    [#link("https://containrrr.dev/watchtower/")[Watchtower]],
    [Автоматическое обновление контейнеров],
    [—],
    [Инфраструктура],
  ),
  caption: [Компоненты системы и их функции],
) <components-table>

== Сетевая архитектура

=== Физическая сеть домашней лаборатории

Перед рассмотрением виртуальных сетей Docker необходимо описать физическую инфраструктуру, в которой развёрнута система:

- *Роутер на базе OpenWrt* — маршрутизирует весь трафик домашней сети, управляет правилами firewall, обеспечивает базовую DNS инфраструктуру.

- *Управляемый L3 коммутатор* — обеспечивает физическую связность устройств в сети. Используется VLAN сегментация, однако описана она не будет, так как выходит за рамки простой пользовательской конфигурации. При желании, энтузиаст-читатель этой курсовой работы может изучить этот вопрос самостоятельно.

- *Firewall с маркировкой трафика* — реализован на роутере OpenWrt. Использует списки доменов и CIDR диапазонов для маркировки трафика. Помеченные ресурсы автоматически направляются в VPN туннель через sign-box. Списки для маршрутизации берутся из проекта #link("https://podkop.net/")[podkop.net].

- *Каскадная DNS инфраструктура* — трёхуровневая система разрешения имён:
  1. *dnsmasq* (базовый DNS роутера) — первичная обработка запросов, кеширование, локальные записи
  2. *sign-box DNS* — маркировка доменов для firewall, определение маршрутизации через VPN
  3. *AdGuardHome* — фильтрация рекламного трафика, DOH/DOT к публичным провайдерам

Конфигурация AdGuardHome использует балансировку между несколькими зашифрованными DNS провайдерами:

#figure(
  ```yaml
  # Основные DNS с шифрованием (DOT/DOH)
  upstream:
    - https://dns10.quad9.net/dns-query
    - https://cloudflare-dns.com/dns-query
    - https://dns.google/dns-query
    - tls://dns10.quad9.net
    - tls://1.1.1.1
    - tls://dns.google

  # Bootstrap DNS (для разрешения имён основных DNS)
  bootstrap-dns:
    - 9.9.9.10          # Quad9 (основной)
    - 149.112.112.10    # Quad9 (резервный)
    - 2620:fe::10       # Quad9 IPv6
    - 2620:fe::fe:10    # Quad9 IPv6 резервный

  # Fallback DNS (незашифрованные, крайний случай)
  fallback-dns:
    - 1.1.1.1           # Cloudflare
    - 1.0.0.1           # Cloudflare резервный
    - 8.8.8.8           # Google DNS
    - 8.8.4.4           # Google DNS резервный
  ```,
  caption: [Конфигурация DNS балансировщика AdGuardHome],
) <adguard-dns-config>

Такая архитектура обеспечивает отказоустойчивость, приватность через шифрование DNS запросов и автоматическую маршрутизацию специфичного трафика через VPN.

=== Виртуальные сети Docker

Каждый функциональный блок инфраструктуры изолирован в собственной виртуальной сети Docker. Контейнеры внутри одного блока видят друг друга и могут взаимодействовать напрямую по имени хоста, что обеспечивает логическую организацию.

Все остальные виртуальные сети в рамках Docker контейнеров:

- *media-network* — сеть для всех медиа-сервисов (Jellyfin, Sonarr, Radarr, Lidarr, Prowlarr, Jellyseerr, qBittorrent, FileFlows). Обеспечивает взаимодействие между компонентами автоматизации и потоковой передачи.
- *proxiable* — публичная сеть для сервисов, доступных через Nginx Proxy Manager. Позволяет обратному прокси маршрутизировать запросы к нужным контейнерам.
- *monitoring* — выделенная сеть для системы мониторинга (Prometheus, Grafana, Node Exporter). Изолирует сбор метрик от основной инфраструктуры.
- *vpn* — сеть для VPN контейнера WireGuard. Используется qBittorrent для приватных скачиваний через зашифрованное соединение.

Такая организация позволяет контейнерам обращаться друг к другу по имени (например, `http://sonarr:8989`), исключая необходимость в фиксированных IP адресах и упрощая конфигурацию.

== Взаимодействие контейнеров

Инфраструктура содержит множество потоков взаимодействия между сервисами. Ниже описан один из самых сложных флоу — полная автоматизация загрузки и каталогизации медиа-контента, который начинается с пользовательского интерфейса.

- Пользователь подключается к *Nginx Proxy Manager* — единой точке входа для всех интерактивных сервисов. Прокси маршрутизирует запрос к *Jellyseerr* в виртуальной Docker сети.
- Пользователь через *Jellyseerr* отправляет запрос на фильм или сериал
- Запрос автоматически создаётся в *Sonarr* (сериалы) или *Radarr* (фильмы) через REST API
- *Sonarr* / *Radarr* отправляют поисковый запрос в *Prowlarr* (агрегатор индексеров торрентов) для поиска торренто-ссылок
- *Sonarr* / *Radarr* отправляют найденные торренты в *qBittorrent* через REST API для загрузки
- *qBittorrent* работает в виртуальной сети *WireGuard* для обеспечения приватности скачиваний
- Загруженные файлы сохраняются в общем хранилище (*File Storage*)
- *FileFlows* автоматически обрабатывает (транскодирует) видео файлы при необходимости
- *Jellyfin* периодически сканирует хранилище и каталогизирует готовый контент, делая его доступным пользователям через сеть

#figure(
  image("diagrams/media-flow.png", width: 100%),
  caption: [Взаимодействия контейнеров автоматизации медиа-контента],
) <media-flow-diagram>

Помимо основного потока, инфраструктура содержит ряд автоматических процессов, недоступных для прямого пользовательского управления, а также простых связок взаимодействий между сервисом и обратным прокси:

- *Watchtower* — мониторит сокет демона Docker, периодически проверяет наличие обновлений для образов контейнеров и автоматически перезапускает сервисы при наличии новых версий. Такой подход позволяет содержать инфраструктуру в актуальном состоянии без ручного вмешательства.

- *Node Exporter* и *cAdvisor* — собирают метрики системы и контейнеров в реальном времени, отправляя их в *Prometheus* для хранения и анализа. *Grafana* визуализирует эти метрики в виде графиков и дашбордов.

- *Публично доступные сервисы* — ряд компонентов (*Jellyfin*, *Vaultwarden*, *Homarr* и другие) доступны конечному пользователю напрямую через их HTTP/HTTPS порты, проксированные *Nginx Proxy Manager*.

= Выбор оборудования

== Профиль потребления ресурсов

Перед развертыванием инфраструктуры необходимо понимать реальные требования к оборудованию. В отличие от облачных сервисов, где потребление зачастую не волнует нас, домашняя лаборатория требует явного расчёта ресурсов.

=== Потребление оперативной памяти

В состоянии покоя (без активных пользователей и обработки) все сервисы инфраструктуры в сумме занимают не более *6 гигабайт оперативной памяти*. Это достаточно скромный объём, что позволяет развертывать систему на оборудовании с 8–16 ГБ ОЗУ.

Основные потребители:

- *FileFlows* (транскодирование). По умолчанию содержит 3 параллельных ранера (worker) для одновременной обработки видео. При транскодировании видеоконтента, даже 4K с высоким битрейтом (80 тыс кбит/с), один ранер занимает примерно *1 гигабайт памяти*, однако нагрузка на центральный процессор отсутствует полностью — вся работа выполняется на видеокарте через NVIDIA NVENC/NVDEC ускорители.

- *Jellyfin* (потоковая передача). Аналогично FileFlows использует NVIDIA GPU ускорители для транскодирования и имеет сопоставимое потребление памяти (около 1 ГБ за сеанс при транскодировании). Оба сервиса используют единый CLI плагин FFmpeg, что обеспечивает идентичное поведение и потребление ресурсов. *Важный момент*: Jellyfin разумно избегает ненужного транскодирования — если контент представлен в кодеке, который может аппаратно воспроизвести клиент (например, HEVC на современных мобильных устройствах), транскодирование не происходит вообще. Дополнительно, Jellyfin кеширует результаты транскодирования, поэтому если множество пользователей одновременно смотрят один и тот же фильм, видеокодек "прогоняется" только один раз, остальные получают кеш из хранилища.

- *Grafana* (мониторинг) и *Homarr* (дашбоард). Эти сервисы могут занимать значительный объём памяти (до 500 МБ–1 ГБ) вследствие сложного пользовательского интерфейса.

- *Остальные сервисы*. Nginx Proxy Manager просто маршрутизирует трафик и периодически обновляет SSL сертификаты — занимает минимум памяти. Watchtower мониторит сокет демона Docker, периодически проверяет обновления образов и перезапускает контейнеры — также не требователен к ресурсам. Медиа-сервисы (Sonarr, Radarr, Lidarr, Prowlarr, Jellyseerr) выполняют лишь API запросы и управление метаданными — их потребление пренебрежимо мало.

=== Потребление процессора

Инфраструктура всех приложений спроектирована таким образом, чтобы минимизировать нагрузку на центральный процессор. Большинство операций либо асинхронные (проверка обновлений, сбор метрик), либо
вовсе I/O-bound (работа с диском, сетью). #underline[Единственным исключением является видеотранскодирование, которое полностью разгружено на видеокарту].

Таким образом, процессор может быть относительно скромным — достаточно 4–6 ядер для обеспечения параллельной работы контейнеров и фоновых задач. При использовании GPU ускорения нагрузка на CPU при транскодировании практически отсутствует.

=== Требования к хранилищу

Хранилище состоит из двух компонентов:

- *Системный диск* (для Docker и конфигурации). Требуется минимум 100–150 ГБ SSD для хранения образов контейнеров, конфигурационных файлов и баз данных сервисов.

- *Медиа-хранилище* (для контента). Объём зависит от размера коллекции фильмов, сериалов и музыки. Для комфортного использования рекомендуется от 1–2 ТБ и выше. Тип хранилища может быть как SSD (для максимальной производительности), так и HDD (для экономии бюджета, так как медиа в основном читается последовательно).

== NVIDIA GPU

Если планируется транскодирование видеоконтента или использование аппаратного ускорения потоковой передачи, рекомендуется видеокарта NVIDIA с поддержкой CUDA.

Требования:

- Видеокарта: NVIDIA GeForce GTX 1050 и выше (поддержка NVENC/NVDEC)
- Драйверы: NVIDIA Driver 450.x и выше

Система полностью функциональна и без видеокарты, однако транскодирование видео будет выполняться на процессоре, что может быть медленным при обработке множественных потоков или 4K контента.

= Практическая реализация

== Развертывание с Docker Compose

=== Docker Compose как инструмент развертывания

Все сервисы инфраструктуры определены в файлах конфигурации *docker-compose.yml*, которые описывают образы контейнеров, переменные окружения, сетевые подключения и тома хранения. Docker Compose позволяет развернуть всю систему одной командой без необходимости запускать каждый контейнер вручную.

Каждый функциональный блок (медиа-сервисы, мониторинг, инфраструктура) имеет собственный каталог в `/src/` с `docker-compose.yml` файлом. Разделение на отдельные файлы обеспечивает модульность и позволяет включать или отключать компоненты по необходимости.

=== Режимы хранения данных

Docker предоставляет два основных способа монтирования хранилища:

- *Named volumes* — управляемые Docker тома, хранящиеся в стандартной директории хоста (обычно `/var/lib/docker/volumes/`). Идеальны для конфигурационных файлов и баз данных, так как не требуют явного указания пути и автоматически резервируются.

- *Bind mounts* — прямое подключение директорий хоста к контейнерам. Используются для медиа-хранилища и пользовательских конфигураций, позволяя адаптировать пути под разные системы. Проект поддерживает оба режима: базовый вариант использует именованные тома, а расширенный — `docker-compose.bind.yml` для переопределения путей на пользовательское хранилище.

=== Структура docker-compose.yml

Конфигурация использует стандартный синтаксис YAML с определением сервисов, сетей и томов. Пример базовой конфигурации для прокси-слоя:

#figure(
  ```yaml
  services:
    nginx-proxy-manager:
      image: jc21/nginx-proxy-manager:latest
      container_name: nginx-proxy-manager
      restart: unless-stopped
      ports:
        - "80:80"
        - "443:443"
        - "81:81"
      environment:
        DISABLE_IPV6: 'true'
      volumes:
        - npm-data:/data
        - npm-letsencrypt:/etc/letsencrypt
      networks:
        - proxiable

  volumes:
    npm-data:
    npm-letsencrypt:

  networks:
    proxiable:
      external: true
  ```,
  caption: [Пример конфигурации Nginx Proxy Manager],
) <nginx-compose-example>

Каждый сервис описывается блоком с параметрами:
- `image` — образ Docker из реестра (Docker Hub или другого)
- `container_name` — имя контейнера в системе
- `restart` — политика перезапуска (unless-stopped, always и т.д.)
- `ports` — проброс портов хоста на контейнер
- `environment` — переменные окружения, параметры конфигурации
- `volumes` — монтирование хранилища
- `networks` — подключение к виртуальным сетям Docker

=== Переменные окружения и .env файлы

Для обеспечения гибкости и безопасности, чувствительные данные (пароли, API ключи) и пути хранения определяются в файлах `.env`, которые загружаются автоматически. Пример структуры:

#figure(
  ```
  JELLYFIN_API_KEY=your_secret_key
  HOST_APPDATA=/mnt/media/data
  TRAEFIK_DASHBOARD_USER=admin
  ```,
  caption: [Пример переменных окружения в файле .env],
) <env-example>

Переменные в `docker-compose.yml` подставляются через синтаксис `${VARIABLE_NAME}`, что позволяет переносить конфигурацию между системами без изменения основного файла.

=== Порядок запуска контейнеров

Хотя Docker Compose может запустить все сервисы параллельно, рекомендуемый порядок обеспечивает корректную инициализацию зависимостей:

1. Создание необходимых Docker сетей (если используется `external: true`)
2. Запуск Nginx Proxy Manager (entry point для других сервисов)
3. Запуск DNS сервера (AdGuardHome) для локального разрешения имён
4. Запуск VPN контейнера (WireGuard) для приватных скачиваний
5. Запуск остальных сервисов в произвольном порядке

Команда для запуска всех контейнеров в директории:

```
docker compose up -d
```

Для запуска конкретного стека с переопределением путей:

```
HOST_APPDATA=/mnt/custom/path docker compose -f docker-compose.yml -f docker-compose.bind.yml up -d
```

== Конфигурация Nginx Proxy Manager

=== Инициализация и доступ к админ-панели

После запуска контейнера Nginx Proxy Manager необходимо войти в администраторскую панель для конфигурации. По умолчанию панель доступна по адресу `http://localhost:81` с учётными данными по умолчанию (admin\@example.com / changeme). После первого входа рекомендуется изменить пароль администратора через раздел Settings.

=== Создание SSL сертификата

Для безопасного HTTPS соединения требуется SSL сертификат. Nginx Proxy Manager поддерживает интеграцию с Let's Encrypt для автоматического получения и обновления сертификатов.

Перейдите на вкладку *Certificates* в верхней навигации:

#figure(
  image("images/nginx-proxy-manager-add-ssl-via-dns.png", width: 100%),
  caption: [Вкладка Certificates в Nginx Proxy Manager],
) <nginx-cert-tab>

Let's Encrypt предоставляет два метода подтверждения владения доменом:

- *HTTP метод* — требует открытия портов 80 на интернета и доступности домена с интернета. Подходит для публичных доменов, но требует явного port forwarding на маршрутизаторе.

- *DNS метод* — подтверждение через создание DNS записей у вашего DNS провайдера. Не требует открытия портов и более безопасен для приватных/локальных доменов. Использует API вашего DNS провайдера (Cloudflare, Route53, и т.д.) для автоматического создания временных записей.

Для локальной инфраструктуры рекомендуется *DNS метод*.

Нажмите кнопку "Add Certificate" и выберите "Let's Encrypt via DNS":

#figure(
  image("images/nginx-proxy-manager-add-ssl-dns-options.png", width: 70%),
  caption: [Диалог добавления Let's Encrypt сертификата через DNS],
) <nginx-dns-dialog>

В поле *Domain Names* введите wildcard домен для вашей локальной сети, например `*.example.lan`. Это позволит использовать один сертификат для всех поддоменов (sonarr.example.lan, radarr.example.lan и т.д.).

В выпадающем списке *DNS Provider* выберите вашего провайдера DNS (Cloudflare, Quad9, и т.д.) и введите необходимые учётные данные — API токен, логин/пароль или другую информацию, требуемую провайдером. Nginx Proxy Manager автоматически создаст DNS записи для подтверждения владения доменом и получит сертификат.

После успешного создания сертификат появится в списке и будет автоматически обновляться за 30 дней до истечения.

=== Добавление хостов для прокси-маршрутизации

После создания SSL сертификата необходимо добавить хосты — правила маршрутизации трафика к контейнерам. Перейдите на вкладку *Hosts* и нажмём кнопку "Add Proxy Host":

#figure(
  image("images/nginx-proxy-manager-add-host.png", width: 100%),
  caption: [Вкладка Hosts для управления прокси-хостами],
) <nginx-hosts-tab>

Откроется диалог добавления нового Proxy Host с несколькими вкладками. Начнём с вкладки *Details*:

#figure(
  image("images/nginx-proxy-manager-sonarr-configure-step-1.png", width: 55%),
  caption: [Диалог добавления Proxy Host с параметрами маршрутизации],
) <nginx-proxy-dialog>

- *Domain Names* — доменное имя, соответствующее вашему wildcard сертификату, например `sonarr.example.lan` для сервиса Sonarr.

- *Forward Hostname / IP* — имя сервиса в Docker сети. *Важно*: это НЕ `container_name`, а лейбл сервиса из `docker-compose.yml` (строка `sonarr:` в блоке `services:`). Docker DNS автоматически разрешит это имя в IP контейнера внутри сети.

- *Forward Port* — порт, на котором слушает сервис согласно конфигурации (например, 8989 для Sonarr, 8096 для Jellyfin).

- *Scheme* — протокол (HTTP или HTTPS) для взаимодействия с контейнером. Обычно используется HTTP, так как контейнеры общаются внутри локальной Docker сети без необходимости в HTTPS.

- *Cache Assets* — отключите для динамического контента (Sonarr, Radarr, API сервисы). Включение этой опции приведёт к кешированию ответов и неправильному отображению обновляющихся данных.

- *Block Common Exploits* — оставьте включённым для защиты от распространённых векторов атак.

#figure(
  image("images/nginx-proxy-manager-sonarr-configure-step-2.png", width: 100%),
  caption: [Вкладка SSL для настройки сертификата и безопасности],
) <nginx-ssl-tab>

- *SSL Certificate* — выпадающий список с доступными сертификатами. Выбираем созданный wildcard сертификат.
- *Force SSL* — опиция включения принудительного перенаправления HTTP трафика на HTTPS.
- *HSTS Enabled* — опция добавления включения HTTP Strict Transport Security.
- *HTTP/2 Support* — поддержка современного протокола HTTP/2.

После сохранения первого хоста (например, для Sonarr) по аналогии создаём все остальные сервисы. Для каждого сервиса необходимо создать отдельный хост с соответствующим доменным именем, лейблом контейнера и портом согласно таблице @components-table.

== Конфигурация Prowlarr

=== Инициализация и методы доступа

Prowlarr — агрегатор индексеров торрентов, который управляет подключением к торрент-сайтам и предоставляет единый интерфейс для поиска. После запуска контейнера Prowlarr доступен по адресу `https://prowlarr.example.lan` (через Nginx Proxy Manager).

При первом входе система предложит выбрать метод защиты:

- *Аутентификация по паролю* — рекомендуется для приватных сетей. Установите надёжный пароль и используйте его при каждом входе.

- *Веб-форма* — более простой вариант, но менее безопасный. Используйте только в изолированных локальных сетях.

Выберите один из методов и продолжите инициализацию.

=== Добавление индексаторов

После инициализации перейдите на главную страницу Prowlarr:

#figure(
  image("images/prowlarr-main-page-add-new-indexer.png", width: 100%),
  caption: [Главная страница Prowlarr с кнопкой добавления индексера],
) <prowlarr-main>

Нажмите кнопку "Add New Indexer" (или "+" в левой панели). Откроется список всех доступных индексаторов:

#figure(
  image("images/prowlarr-indexers-list.png", width: 100%),
  caption: [Список доступных индексаторов для добавления],
) <prowlarr-indexers>

Список содержит более сотни индексаторов, поддерживаемых и обновляемых сообществом Prowlarr. Каждый индексатор может быть:

- *Публичным* — доступен без регистрации. Просто выберите и создайте индексатор.

- *Semi-private* — доступны с бесплатной регистрацией или с минимальными ограничениями. Требуют заполнения логина и пароля, но могут быть созданы любым пользователем без приглашения.

- *Приватным* — требует учётные данные (логин, пароль, API ключ или токен). После выбора приватного индексатора вам будет предложено заполнить поле для авторизации (обычно это приватный URL с токеном или API ключом). Доступ ограничен зарегистрированными пользователями или членами сообщества.

Общий процесс:

1. Найдите нужный индексатор в списке (используйте поиск)
2. Нажмите на него для открытия конфигурации
3. Если это приватный индексатор, введите учётные данные авторизации
4. Нажмите "Add Indexer" для добавления

После добавления индексатора он становится доступным для поиска из Sonarr, Radarr и Lidarr через встроенный API Prowlarr. Все поиски и запросы будут автоматически распределяться между добавленными индексаторами.

=== Добавление клиента загрузок

Prowlarr должен знать, на какой клиент отправлять найденные торренты для загрузки. Для этого необходимо добавить qBittorrent в качестве download client.

Перейдите в раздел *Settings* → *Download Clients*:

#figure(
  image("images/prowlarr-settings-download-clients.png", width: 100%),
  caption: [Раздел Download Clients в настройках Prowlarr],
) <prowlarr-download-clients>

Нажмите кнопку "+" для добавления нового клиента и выберите *qBittorrent* из списка:

#figure(
  image("images/prowlarr-add-qbittorrent-download-client.png", width: 85%),
  caption: [Конфигурация qBittorrent как download client],
) <prowlarr-qbit-config>


*Ключевой момент*: так как qBittorrent запущен в виртуальной сети WireGuard (VPN) для приватности скачиваний, в поле *Host* необходимо указать лейбл контейнера VPN сервера — это `wireguard`. Docker DNS автоматически разрешит это имя в IP адрес контейнера WireGuard, через который будет маршрутизироваться весь трафик qBittorrent.

Остальные параметры (Port, Username, Password) остаются со значениями по умолчанию или заполняются в зависимости от конкретной конфигурации qBittorrent в docker-compose. После сохранения Prowlarr сможет отправлять найденные торренты непосредственно в qBittorrent для загрузки.
